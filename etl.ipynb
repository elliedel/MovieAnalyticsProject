{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "457f3464",
   "metadata": {},
   "source": [
    "# Movie Analytics Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4225e106",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f14f777",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "from datetime import datetime\n",
    "import io\n",
    "import json\n",
    "import os\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import requests\n",
    "from sqlalchemy import create_engine\n",
    "from dotenv import load_dotenv\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, when"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d39c1ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "zip_url = os.getenv(\"DATASOURCE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec51bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Exception occurred during processing of request from ('127.0.0.1', 54993)\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\JLC04\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\socketserver.py\", line 317, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"c:\\Users\\JLC04\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\socketserver.py\", line 348, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"c:\\Users\\JLC04\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\socketserver.py\", line 361, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"c:\\Users\\JLC04\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\socketserver.py\", line 755, in __init__\n",
      "    self.handle()\n",
      "  File \"c:\\Users\\JLC04\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyspark\\accumulators.py\", line 295, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"c:\\Users\\JLC04\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyspark\\accumulators.py\", line 267, in poll\n",
      "    if self.rfile in r and func():\n",
      "                           ^^^^^^\n",
      "  File \"c:\\Users\\JLC04\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyspark\\accumulators.py\", line 271, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\JLC04\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyspark\\serializers.py\", line 594, in read_int\n",
      "    length = stream.read(4)\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\JLC04\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\socket.py\", line 706, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession\\\n",
    "    .builder \\\n",
    "    .appName(\"Movie_Analytics\") \\\n",
    "    .config(\"spark.jars\", os.getenv(\"MYSQL_CONNECTOR_JAR\")) \\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n",
    "jdbc_url = \"jdbc:mysql://localhost:3306/finalprojectschema\"\n",
    "properties = {\n",
    "    \"user\": os.getenv(\"USER\"),\n",
    "    \"password\": os.getenv(\"PASSWORD\"),\n",
    "    \"driver\": \"com.mysql.cj.jdbc.Driver\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbbd254",
   "metadata": {},
   "source": [
    "## Initialize ETL Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe0fda1",
   "metadata": {},
   "source": [
    "### Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a6bc31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(zip_url):\n",
    "    \"\"\"\n",
    "    Extracts CSV and JSON files from a ZIP file located at the provided URL.\n",
    "    Only files within the 'project_data/' directory are processed.\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of three DataFrames:\n",
    "        (movies_main_df, movie_extended_df, ratings_df)\n",
    "    \"\"\"\n",
    "\n",
    "    response = requests.get(zip_url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        buffer = io.BytesIO(response.content)\n",
    "        dataframes = {}\n",
    "\n",
    "        with zipfile.ZipFile(buffer, \"r\") as zip_ref:\n",
    "            for file_name in zip_ref.namelist():\n",
    "\n",
    "                if file_name.startswith(\"project_data/\") and not file_name.endswith(\"/\"):\n",
    "                    print(\"Processing:\", file_name)\n",
    "                    clean_name = file_name.split(\"/\")[-1].split(\".\")[0]\n",
    "\n",
    "                    with zip_ref.open(file_name) as f:\n",
    "                        if file_name.endswith(\".csv\"):\n",
    "                            dataframes[f\"{clean_name}_df\"] = pd.read_csv(f)\n",
    "\n",
    "                        elif file_name.endswith(\".json\"):\n",
    "                            dataframes[f\"{clean_name}_df\"] = pd.read_json(f)\n",
    "\n",
    "        print(\"\\nExtracted the data into a pandas dataframe\")\n",
    "        return (dataframes.get(\"movies_main_df\"), \n",
    "                dataframes.get(\"movie_extended_df\"), \n",
    "                dataframes.get(\"ratings_df\"))\n",
    "\n",
    "    else:\n",
    "        print(\"Failed to download the ZIP file\")\n",
    "        return None, None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9b2fdd",
   "metadata": {},
   "source": [
    "### Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c189de1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_dim_movies(df):\n",
    "    \"\"\"\n",
    "    Transforms the movie DataFrame into a dimension table, which returns a DataFrame suitable for the 'dim_movies' table.\n",
    "    \n",
    "    Steps:\n",
    "    - Filters out rows with non-numeric IDs.\n",
    "    - Converts release dates to a consistent day/month/year format.\n",
    "    - Drops budget and revenue columns.\n",
    "    - Renames 'id' to 'movie_id' and ensures it's an integer.\n",
    "    - Removes rows with missing movie_id or title.\n",
    "    \"\"\"\n",
    "    \n",
    "    df = df[df[\"id\"].str.isnumeric()] \n",
    "    df.loc[:, \"release_date\"] = pd.to_datetime(df[\"release_date\"], format=\"mixed\").dt.strftime(\"%m/%d/%Y\")\n",
    "    df = df.drop(columns=[\"budget\", \"revenue\"]).rename(columns={\"id\": \"movie_id\"})\n",
    "    df[\"movie_id\"] = df[\"movie_id\"].astype(int)\n",
    "    df.dropna(subset=[\"movie_id\", \"title\"], inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de9a8072",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_dim_genres(df):\n",
    "    \"\"\"\n",
    "    Transforms the genre information into a dimension table, and returns the dim_genres dataframe.\n",
    "\n",
    "    Steps:\n",
    "    - Splits the 'genres' string into lists and explodes them into separate rows.\n",
    "    - Converts 'id' to numeric and renames it to 'movie_id'.\n",
    "    - Drops unrelated columns.\n",
    "    - Drops any rows with missing values and ensures 'movie_id' is an integer.\n",
    "    \"\"\"\n",
    "        \n",
    "    df[\"genres\"] = df[\"genres\"].str.split(\",\").reset_index(drop=True)\n",
    "    df = df.explode(\"genres\")\n",
    "    df[\"id\"] = pd.to_numeric(df[\"id\"], errors=\"coerce\")\n",
    "    df = df.drop(columns=[\"production_companies\", \"production_countries\", \"spoken_languages\"]).rename(columns={\"id\": \"movie_id\", \"genres\": \"genre\"}).dropna()\n",
    "    df[\"movie_id\"] = df[\"movie_id\"].astype(int)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11709594",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_dim_companies(df):\n",
    "    \"\"\"\n",
    "    Transforms the production company information into a dimension table, and returns the dim_companies dataframe.\n",
    "\n",
    "    Steps:\n",
    "    - Splits 'production_companies' into lists and explodes them into separate rows.\n",
    "    - Converts 'id' to numeric and renames it to 'movie_id'.\n",
    "    - Drops unrelated columns and rows with missing data.\n",
    "    - Ensures 'movie_id' is an integer.\n",
    "    \"\"\"\n",
    "    \n",
    "    df[\"production_companies\"] = df[\"production_companies\"].str.split(\",\").reset_index(drop=True)\n",
    "    df = df.explode(\"production_companies\")\n",
    "    df[\"id\"] = pd.to_numeric(df[\"id\"], errors=\"coerce\")\n",
    "    df = df.drop(columns=[\"genres\", \"production_countries\", \"spoken_languages\"]).rename(columns={\"id\": \"movie_id\", \"production_companies\": \"production_company\"}).dropna()\n",
    "    df[\"movie_id\"] = df[\"movie_id\"].astype(int)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5206cbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_eval(val):\n",
    "    \"\"\"\n",
    "    Safely evaluates a string representation of a list or dictionary into an object,\n",
    "    for the purpose of columns with stringified dictionary as a data point (For stringified lists/dictionaries datapoints).\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(val, str):\n",
    "        return ast.literal_eval(val)\n",
    "    \n",
    "    return val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a950852a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_dim_countries(df):\n",
    "    \"\"\"\n",
    "    Transforms country information into a dimension table, and returns the dim_countries dataframe.\n",
    "\n",
    "    Steps:\n",
    "    - Parses 'production_countries' JSON strings into Python objects.\n",
    "    - Explodes the list of countries into separate rows.\n",
    "    - Normalizes country dictionaries into separate columns.\n",
    "    - Renames and filters relevant columns.\n",
    "    - Ensures 'movie_id' is an integer.\n",
    "    \"\"\"\n",
    "    \n",
    "    df[\"production_countries\"] = df[\"production_countries\"].apply(safe_eval)\n",
    "    df = df.explode(\"production_countries\")\n",
    "    df[\"id\"] = pd.to_numeric(df[\"id\"], errors=\"coerce\")\n",
    "    df = df .dropna(subset=[\"production_countries\"]).reset_index(drop=True)\n",
    "    df = pd.concat([df[\"id\"], pd.json_normalize(df[\"production_countries\"])], axis=1).rename(columns={\"id\": \"movie_id\", \"iso_3166_1\": \"country_code\", \"name\": \"country\"}).dropna()\n",
    "    df[\"movie_id\"] = df[\"movie_id\"].astype(int)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31cf5ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_dim_languages(df):\n",
    "    \"\"\"\n",
    "    Transforms the raw movie data to create the dimension table for spoken languages, returns the dim_languages dataframe.\n",
    "\n",
    "    Steps:\n",
    "    - Converts stringified lists/dictionaries to Python objects\n",
    "    - Explodes the list so each language becomes a separate row\n",
    "    - Normalizes the language dictionaries into individual columns\n",
    "    - Renames and cleans up the dataframe to match the star schema\n",
    "    \"\"\"\n",
    "    \n",
    "    df[\"spoken_languages\"] = df[\"spoken_languages\"].apply(safe_eval)\n",
    "    df = df.explode(\"spoken_languages\")\n",
    "    df[\"id\"] = pd.to_numeric(df[\"id\"], errors=\"coerce\")\n",
    "    df = df .dropna(subset=[\"spoken_languages\"]).reset_index(drop=True)\n",
    "    df = pd.concat([df[\"id\"], pd.json_normalize(df[\"spoken_languages\"])], axis=1).rename(columns={\"id\": \"movie_id\", \"iso_639_1\": \"language_code\", \"name\": \"language\"}).dropna()\n",
    "    df[\"movie_id\"] = df[\"movie_id\"].astype(int)   \n",
    "   \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "acdc3e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_fact_table(df1, df2):\n",
    "    \"\"\"\n",
    "    Transforms and merges ratings and numerical movie columns into a fact table, returns the fact_table.\n",
    "\n",
    "    - Gets the ratings and movies_main dataframe\n",
    "    - Normalizes nested rating summary columns\n",
    "    - Converts epoch timestamps to readable dates\n",
    "    - Converts string values to numeric (handling errors)\n",
    "    - Fills missing rating/financial fields with default values\n",
    "    - Merges both datasets on 'movie_id' to form a complete fact table\n",
    "\n",
    "    Args:\n",
    "        df1 (pd.DataFrame): The ratings dataframe from 'ratings_df'\n",
    "        df2 (pd.DataFrame): The main movie dataframe from 'movies_main_df'\n",
    "    \"\"\"\n",
    "    \n",
    "    df_summary = pd.json_normalize(df1[\"ratings_summary\"])\n",
    "    df1[df_summary.columns] = df_summary\n",
    "\n",
    "    df1[\"last_rated\"] = pd.to_datetime(df1[\"last_rated\"], unit=\"s\").dt.strftime(\"%m/%d/%Y\")\n",
    "\n",
    "    df1.drop(columns=\"ratings_summary\", inplace=True)\n",
    "\n",
    "    df2[\"id\"] = pd.to_numeric(df2[\"id\"], errors=\"coerce\")\n",
    "    df2[\"budget\"] = pd.to_numeric(df2[\"budget\"], errors=\"coerce\")\n",
    "    df2[\"revenue\"] = pd.to_numeric(df2[\"revenue\"], errors=\"coerce\")\n",
    "\n",
    "    fill_df1 = [\"last_rated\", \"avg_rating\", \"total_ratings\", \"std_dev\"]\n",
    "    df1[fill_df1] = df1[fill_df1].fillna(0)\n",
    "    df2[[\"budget\", \"revenue\"]] = df2[[\"budget\", \"revenue\"]].fillna(0)\n",
    "\n",
    "    df2 = df2.dropna(subset=[\"id\"]).drop(columns=[\"title\", \"release_date\"]).rename(columns={\"id\": \"movie_id\"})\n",
    "    df2[\"movie_id\"] = df2[\"movie_id\"].astype(int)\n",
    "\n",
    "    df = pd.merge(df1, df2, on=\"movie_id\", how=\"outer\")\n",
    "\n",
    "    df = df.drop_duplicates(subset=[\"movie_id\"], keep=\"first\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02611190",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5281619",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(DIM_movies, DIM_genres, DIM_companies, DIM_countries, DIM_languages, FACT_movies, engine=None):\n",
    "    \"\"\"\n",
    "    - Create MySQL engine if not provided\n",
    "    - Convert PySpark DataFrames to pandas (for exporting)\n",
    "    - Store DataFrames to MySQL\n",
    "    \"\"\"\n",
    "\n",
    "    if engine is None:\n",
    "        dbuser = os.getenv(\"USER\")\n",
    "        dbpassword = os.getenv(\"PASSWORD\")\n",
    "        dbname = \"trial_projschema\"\n",
    "        engine = create_engine(f\"mysql+mysqlconnector://{dbuser}:{dbpassword}@localhost/{dbname}\")\n",
    "    \n",
    "    DIM_movies_pd = DIM_movies.toPandas()\n",
    "    DIM_genres_pd = DIM_genres.toPandas()\n",
    "    DIM_companies_pd = DIM_companies.toPandas()\n",
    "    DIM_countries_pd = DIM_countries.toPandas()\n",
    "    DIM_languages_pd = DIM_languages.toPandas()\n",
    "    FACT_movies_pd = FACT_movies.toPandas()\n",
    "    \n",
    "    DIM_movies_pd.to_sql(name=\"dim_movies\", con=engine, index=False, if_exists=\"replace\")\n",
    "    DIM_genres_pd.to_sql(name=\"dim_genres\", con=engine, index=False, if_exists=\"replace\")\n",
    "    DIM_companies_pd.to_sql(name=\"dim_companies\", con=engine, index=False, if_exists=\"replace\")\n",
    "    DIM_countries_pd.to_sql(name=\"dim_countries\", con=engine, index=False, if_exists=\"replace\")\n",
    "    DIM_languages_pd.to_sql(name=\"dim_languages\", con=engine, index=False, if_exists=\"replace\")\n",
    "    FACT_movies_pd.to_sql(name=\"fact_movies\", con=engine, index=False, if_exists=\"replace\")\n",
    "    \n",
    "    print(\"Data loading complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fd0db7",
   "metadata": {},
   "source": [
    "## Main Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3db4e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: project_data/movies_main.csv\n",
      "Processing: project_data/movie_extended.csv\n",
      "Processing: project_data/ratings.json\n",
      "\n",
      "Extracted the data into a pandas dataframe\n",
      "Transform done...\n"
     ]
    }
   ],
   "source": [
    "movies_main_df, movies_extended_df, ratings_df = extract_data(zip_url)\n",
    "\n",
    "DIM_movies_pd = transform_dim_movies(movies_main_df)\n",
    "DIM_genres_pd = transform_dim_genres(movies_extended_df)\n",
    "DIM_companies_pd = transform_dim_companies(movies_extended_df)\n",
    "DIM_countries_pd = transform_dim_countries(movies_extended_df)\n",
    "DIM_languages_pd = transform_dim_languages(movies_extended_df)\n",
    "FACT_movies_pd = transform_fact_table(ratings_df, movies_main_df)\n",
    "print(\"Transform done...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042e50c8",
   "metadata": {},
   "source": [
    "### PySpark Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43889723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Rating per Movie:\n",
      "+--------+------------------+\n",
      "|movie_id|   avg(avg_rating)|\n",
      "+--------+------------------+\n",
      "|      26|               4.1|\n",
      "|      29|             4.025|\n",
      "|     474|            3.8625|\n",
      "|     964|               2.5|\n",
      "|    1677|               NaN|\n",
      "|    1697|               NaN|\n",
      "|    1806|               1.5|\n",
      "|    1950| 3.909090909090909|\n",
      "|    2040| 3.333333333333333|\n",
      "|    2214|               3.5|\n",
      "|    2250|               3.2|\n",
      "|    2453| 3.285714285714285|\n",
      "|    2529|3.6315789473684212|\n",
      "|    2927|               4.5|\n",
      "|    3091|               4.1|\n",
      "|      65|             2.025|\n",
      "|     191|               3.0|\n",
      "|     418|               3.0|\n",
      "|     541| 4.037671232876712|\n",
      "|     558| 2.666666666666666|\n",
      "+--------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DIM_movies = spark.createDataFrame(DIM_movies_pd)\n",
    "DIM_genres = spark.createDataFrame(DIM_genres_pd)\n",
    "DIM_companies = spark.createDataFrame(DIM_companies_pd)\n",
    "DIM_countries = spark.createDataFrame(DIM_countries_pd)\n",
    "DIM_languages = spark.createDataFrame(DIM_languages_pd)\n",
    "FACT_movies = spark.createDataFrame(FACT_movies_pd)\n",
    "\n",
    "# Average rating per Movie\n",
    "print(\"Average Rating per Movie:\")\n",
    "FACT_movies.groupBy(\"movie_id\").agg(\n",
    "    {\"avg_rating\": \"avg\"}\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "15cceefa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating Categories:\n",
      "+--------+------------------+---------------+\n",
      "|movie_id|        avg_rating|rating_category|\n",
      "+--------+------------------+---------------+\n",
      "|       1|  3.87246963562753|           High|\n",
      "|       2| 3.401869158878504|        Average|\n",
      "|       3| 3.161016949152542|        Average|\n",
      "|       4| 2.384615384615384|            Low|\n",
      "|       5|3.2678571428571432|        Average|\n",
      "|       6| 3.884615384615384|           High|\n",
      "|       7| 3.283018867924528|        Average|\n",
      "|       8|               3.8|           High|\n",
      "|       9|              3.15|        Average|\n",
      "|      10|3.4508196721311473|        Average|\n",
      "|      11| 3.689024390243902|           High|\n",
      "|      12| 2.861111111111111|        Average|\n",
      "|      13|            3.9375|           High|\n",
      "|      14| 3.451612903225806|        Average|\n",
      "|      15| 2.318181818181818|            Low|\n",
      "|      16| 3.948863636363636|           High|\n",
      "|      17| 3.924418604651162|           High|\n",
      "|      18| 3.288461538461538|        Average|\n",
      "|      19| 2.597826086956522|        Average|\n",
      "|      20| 2.538461538461538|        Average|\n",
      "+--------+------------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Categorical Rating by Movies\n",
    "FACT_movies = FACT_movies.withColumn(\n",
    "    \"rating_category\",\n",
    "    when(col(\"avg_rating\") >= 4.5, \"Very High\")\n",
    "    .when((col(\"avg_rating\") >= 3.5) & (col(\"avg_rating\") < 4.5), \"High\")\n",
    "    .when((col(\"avg_rating\") >= 2.5) & (col(\"avg_rating\") < 3.5), \"Average\")\n",
    "    .when((col(\"avg_rating\") >= 1.5) & (col(\"avg_rating\") < 2.5), \"Low\")\n",
    "    .otherwise(\"Very Low\")\n",
    ")\n",
    "print(\"Rating Categories:\")\n",
    "FACT_movies.select(\"movie_id\", \"avg_rating\", \"rating_category\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ac4b275e",
   "metadata": {},
   "outputs": [],
   "source": [
    "FACT_movies.createOrReplaceTempView(\"fact_movies\")\n",
    "DIM_movies.createOrReplaceTempView(\"dim_movies\")\n",
    "DIM_genres.createOrReplaceTempView(\"dim_genres\")\n",
    "DIM_companies.createOrReplaceTempView(\"dim_companies\")\n",
    "DIM_countries.createOrReplaceTempView(\"dim_countries\")\n",
    "DIM_languages.createOrReplaceTempView(\"dim_languages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "88c12030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Rating per Genre:\n",
      "+---------------+----------------+\n",
      "|          genre|avg_genre_rating|\n",
      "+---------------+----------------+\n",
      "|          Crime|             NaN|\n",
      "|        Romance|             NaN|\n",
      "|       TV Movie|             NaN|\n",
      "|       Thriller|             NaN|\n",
      "|      Adventure|             NaN|\n",
      "|        Foreign|             NaN|\n",
      "|          Drama|             NaN|\n",
      "|            War|             NaN|\n",
      "|    Documentary|             NaN|\n",
      "|         Family|             NaN|\n",
      "|        Fantasy|             NaN|\n",
      "|        History|             NaN|\n",
      "|        Mystery|             NaN|\n",
      "|      Animation|             NaN|\n",
      "|          Music|             NaN|\n",
      "|Science Fiction|             NaN|\n",
      "|         Horror|             NaN|\n",
      "|        Western|             NaN|\n",
      "|         Comedy|             NaN|\n",
      "|         Action|             NaN|\n",
      "+---------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Average rating per Genre (using PySpark SQL)\n",
    "print(\"Average Rating per Genre:\")\n",
    "spark.sql(\"\"\"\n",
    "    SELECT dg.genre, AVG(fm.avg_rating) AS avg_genre_rating\n",
    "    FROM fact_movies fm\n",
    "    JOIN dim_genres dg ON fm.movie_id = dg.movie_id\n",
    "    JOIN dim_movies dm ON fm.movie_id = dm.movie_id\n",
    "    GROUP BY dg.genre\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ffa184",
   "metadata": {},
   "source": [
    "### Load to DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de09077d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading complete\n",
      "Load and Pipeline complete.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "dbuser = os.getenv(\"USER\")\n",
    "dbpassword = os.getenv(\"PASSWORD\")\n",
    "dbname = \"trial_projschema\"\n",
    "engine = create_engine(f\"mysql+mysqlconnector://{dbuser}:{dbpassword}@localhost/{dbname}\")\n",
    "load_data(DIM_movies, DIM_genres, DIM_companies, DIM_countries, DIM_languages, FACT_movies, engine)\n",
    "\n",
    "print(\"Load and Pipeline complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
